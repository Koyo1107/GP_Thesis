\chapter{考察}
ここでは本研究が行った実験とその評価についての考察を述べる.
\section{精度の考察}
画面全体を検出した場合の表\tabref{tab:mAP_fig_noweght}と\tabref{tab:mAP_fig}を比較する.
2つの表を比較した際に,大きな違いはFPである.実装したDepth2Jamは画面中央部分のみを検出するように改良したためFPがどの動画においても0という結果になっているが,画面全体を検出する場合ではFPが最大で29まで増加している.
画面両端の1/3部分を検出しないようにした結果,Depth2Jamの正確性が向上したことがこの比較でわかる.
次に,映像5における2つの結果を比較した際に,\tabref{tab:mAP_fig_noweght}においてはF値が0.82と\tabref{tab:mAP_fig}におけるF値の0.33より大幅に上昇している.

\subsection{誤検出}
まず,\ref{sec:exp1}における誤検出の例とその原因についての考察を述べる.
\tabref{tab:exp3_fig}において,映像1においては誤推定されたフレームは存在しないが,映像2においては渋滞ではないのに渋滞だと誤推定されたフレームが存在する.
誤推定されたフレームの例を\figref{fig:mov2miss01}と\figref{fig:mov2miss02}に示す.

% ---------------------------------
\begin{figure}[htbp]
  \begin{minipage}{0.5\hsize}
   \begin{center}
    \includegraphics[width=7cm]{figs/mov2miss/miss01.png}
   \end{center}
   \caption{誤検出の例1}
   \label{fig:mov2miss01}
  \end{minipage}
  \begin{minipage}{0.5\hsize}
  \begin{center}
   \includegraphics[width=7cm]{figs/mov2miss/miss02.png}
  \end{center}
   \caption{誤検出の例2}
   \label{fig:mov2miss02}
  \end{minipage}
 \end{figure}
% ---------------------------------

どちらのフレーム画像においても検出された自動車が中央に寄っており,かつ検出されたBBOXにおける平均G値が100を超えてしまっているので渋滞だと判断してしまっていることがわかる.
実装したDepth2Jamシステムにおいては,画面左右1/3における自動車の検出がされないようにしているが,この検出除外処理は,検出されたBBOXにおける2つのX軸の値のうち,左側つまり小さい方の値のX軸が画面の左右1/3の範囲に含まれる場合に発生する.
このフレームではそのX軸の値が中央1/3の範囲に含まれているためこのような結果になったのだと思われる.
より精度を向上させるために,BBOXにおけるX軸の値のうち,右側つまり値の大きい方のX軸に対しても追加で検出除外処理を設ける必要があると考えられる.

\newpage
\subsection{FNに関する考察}
ここでは,\tabref{tab:mAP_fig}におけるFNに関する考察について述べる.
映像1と映像2に関しては渋滞しているフレームは存在しないのでFNの値も0となっているが,映像3~5および総合においてはFNの値が目立つ.
FNはシステムが渋滞でないと判断したが,実際には渋滞していたフレームであり,現実では信号や渋滞等で自動車が動いていないのにシステムが渋滞だと判断できていなかったフレームである.
そのフレームの例を\figref{fig:fn01}と\figref{fig:fn02}に示す.

% ---------------------------------
\begin{figure}[htbp]
  \begin{minipage}{0.5\hsize}
   \begin{center}
    \includegraphics[width=7cm]{figs/consider/fn01.png}
   \end{center}
   \caption{FNの例1}
   \label{fig:fn01}
  \end{minipage}
  \begin{minipage}{0.5\hsize}
  \begin{center}
   \includegraphics[width=7cm]{figs/consider/fn02.png}
  \end{center}
   \caption{FNの例2}
   \label{fig:fn02}
  \end{minipage}
 \end{figure}
% ---------------------------------

どちらの例も先行車が停車しており,ドライブレコーダーを搭載した自動車も停車している状況である.
そして,検出されたBBOXにおいて,G値の値は70程度となっており,渋滞と判断されていない.
考えられる原因としてはドライバーが車間距離に余裕を持って停車しているため,G値が相対的に小さくなってしまっていることにあると考えられる.
車間距離に余裕を持って停車することは本来推奨される運転のため,余裕を持って車間距離をとっている場合でも渋滞だと推定できる手法を取る必要がある.

% -----------------------考察ここまで ------------------------
\newpage
\section{今後の展望}
実験を通じて,ドライブレコーダーを使用することで渋滞を推定することが可能であることがわかった.
しかし,渋滞推定システムが実用化されるにはいくつか解決しなければならない問題がある.
\subsection{処理時間の問題}
課題のひとつに処理にかかる時間という問題がある.
現状のシステムはあらかじめ用意されたドライブレコーダー映像を処理しているが,Depth2Jamが実用化されるためにはリアルタイムで映像処理ができる必要がある.
しかし,現状のシステムでは１分の動画を処理するのに10分程度かかる.

処理時間の減少を図る方法はいくつか考えられる.
まず,処理する量を減らす手法である.現状のシステムでは深度推定ライブラリと物体検出ライブラリの実行を全ての映像のフレームで行っている.
この処理において,先に物体検出ライブラリで自動車類を検出し,検出できたフレームだけ深度推定ライブラリを実行するという方法である.
深度推定ライブラリを実行する回数を減らすことで総合的な処理時間を減少することが可能なのではないかと考えられる.

\subsection{容量の問題}
加えて車に搭載するには必要な容量が膨大である問題がある.
現状のシステムはTensorFlowライブラリとPyTorchライブラリの両方を利用しているため,実際に自動車に搭載してリアルタイムで検出するにはそれぞれのライブラリが入るほどの記憶容量が必要である.
しかし,現状のNvidia Jetsonといった開発向けのGPU装置はTensorFlowライブラリとPyTorchライブラリの両方を保存できるだけの容量の余裕がない.
この問題を解決する方法の一つとして使用するライブラリをTnsorFlowかPyTorchのどちらか一方に絞るという方法がある.
TensorflowもしくはPyTorchのどちらかに絞ることができれば容量削減と同時に呼び出すライブラリを減らすことができ,処理時間を減らすことが期待できる.

\subsection{精度向上のために}
現状のシステムではstruct2depthの色データーを取得して渋滞か否かを判断しているが,より精度を向上するにはstruct2depthで色を塗られる前の内部情報を取得する方法がある.
内部情報を取得して評価に組み込むことによって色分けして評価するよりもBOXを描写して色情報の平均を取るといった処理がなくなり,より少ない処理で評価まで辿り着ける上,色を塗られることなく評価が実現できる.
色を塗られることなく評価をすることができればより処理時間が少なくなり,また同時に高い制度が期待できる.